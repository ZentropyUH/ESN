{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import os\n",
    "import numpy as np\n",
    "import keras_tuner as kt\n",
    "import matplotlib.pyplot as plt\n",
    "from keras_tuner.tuners import RandomSearch, Hyperband, BayesianOptimization\n",
    "from src.model import ESN\n",
    "from src.utils import load_data\n",
    "from src.model import simple_reservoir\n",
    "from src.customs.custom_initializers import WattsStrogatzNX, InputMatrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input matrix hyperparams\n",
    "\n",
    "# Input scaling factor\n",
    "min_sigma = 0.1\n",
    "max_sigma = 5.0\n",
    "step_sigma = 0.1\n",
    "\n",
    "# Watts-Strogatz hyperparams\n",
    "\n",
    "# degree\n",
    "min_degree = 2\n",
    "max_degree = 10\n",
    "step_degree = 2\n",
    "\n",
    "# spectral radius\n",
    "min_spectral = 0.4\n",
    "max_spectral = 2.0\n",
    "step_spectral = 0.1\n",
    "\n",
    "# rewiring prob\n",
    "min_prob = 0.0\n",
    "max_prob = 1.0\n",
    "step_prob = 0.1\n",
    "\n",
    "# ESN Cell\n",
    "\n",
    "reservoir_units = 2000\n",
    "\n",
    "# leak rate\n",
    "min_leak = 0.1\n",
    "max_leak = 1\n",
    "step_leak = 0.01\n",
    "\n",
    "\n",
    "# Training\n",
    "\n",
    "# regularization (log scale)\n",
    "\n",
    "min_reg = 1e-9\n",
    "max_reg = 1e-4\n",
    "step_reg = 10\n",
    "\n",
    "# This is for the training process\n",
    "\n",
    "iterations = 10 # to make statistics take the mean\n",
    "forecast_length = 2000 # the forecast length used to benchmark the model\n",
    "train_length = 20000 # ammount of points for training\n",
    "\n",
    "max_trials = 500 # This is when not using hyperband. This is the maximum number of trials to be done when searching for the best hyperparameters\n",
    "\n",
    "directory_name = \"Lorenz_Bayesian_Optimization\" # name of the folder that stores the hp exploratory process (lets you continue if broken)\n",
    "project_name = \"lorenz\" # Change when needed\n",
    "\n",
    "continue_where_leftoff = True # self-explanatory\n",
    "\n",
    "overwrite = not continue_where_leftoff # This is the actual parameter used, setting the previous has more sense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is the banana, do not change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyHyperModel(kt.HyperModel):\n",
    "    \n",
    "    def __init__(self, input_shape, forecast_length=2000, data_path=None):\n",
    "        self.input_shape = input_shape\n",
    "        self.forecast_length = forecast_length\n",
    "        self.data_path = data_path\n",
    "    \n",
    "    def build(self, hp):\n",
    "        \n",
    "        self.seed = hp.Int('seed', min_value=0, max_value=1000000)\n",
    "        \n",
    "        input_initializer = InputMatrix(sigma=hp.Float('input_scaling', min_value=min_sigma, max_value=max_sigma, step=step_sigma), seed=self.seed)\n",
    "        \n",
    "        recurrent_initializer = WattsStrogatzNX(\n",
    "            degree=hp.Int('degree', min_value=min_degree, max_value=max_degree, step=step_degree),\n",
    "            spectral_radius=hp.Float('spectral_radius', min_value=min_spectral, max_value=max_spectral, step=step_spectral),\n",
    "            rewiring_p=hp.Float('rewiring_p', min_value=min_prob, max_value=max_prob, step=step_prob),\n",
    "            ones=True,\n",
    "            seed=self.seed\n",
    "        )\n",
    "        \n",
    "        bias_init = keras.initializers.random_uniform(seed=self.seed)\n",
    "        \n",
    "        \n",
    "        reservoir = simple_reservoir(\n",
    "                            #    units=hp.Int('units', min_value=1000, max_value=5000, step=100),\n",
    "                               units=reservoir_units,\n",
    "                               leak_rate=hp.Float('leak_rate', min_value=min_leak, max_value=max_leak, step=step_leak),\n",
    "                               features=self.input_shape[-1],\n",
    "                               input_reservoir_init=input_initializer,\n",
    "                               reservoir_kernel_init=recurrent_initializer,\n",
    "                               input_bias_init=bias_init)\n",
    "        \n",
    "        readout = keras.layers.Dense(self.input_shape[-1], activation=\"linear\", name=\"readout\")\n",
    "        \n",
    "        model = self.model = keras.Model(\n",
    "                inputs=reservoir.inputs,\n",
    "                outputs=readout(reservoir.output),\n",
    "                name=\"ESN\",\n",
    "                )\n",
    "        \n",
    "        return model\n",
    "        \n",
    "    def fit(self, \n",
    "        hp, \n",
    "        model,\n",
    "        iterations=5,\n",
    "        **kwargs):\n",
    "    \n",
    "        results = []\n",
    "\n",
    "        for i in range(iterations):\n",
    "            if os.path.isdir(self.data_path):\n",
    "                data_file = np.random.choice(os.listdir(self.data_path))\n",
    "                data_file = os.path.join(self.data_path, data_file)\n",
    "            else:\n",
    "                data_file = self.data_path\n",
    "\n",
    "            transient_data, train_data, train_target, ftransient, val_data, val_target = (\n",
    "                load_data(data_file, train_length=train_length)\n",
    "            )\n",
    "            \n",
    "            print(f\"Iteration {i + 1} of {iterations}\")\n",
    "            \n",
    "            # Build the model again to include stochasticity in initialization\n",
    "            model = self.build(hp)\n",
    "            \n",
    "            esn = ESN.from_model(model=model, seed=self.seed)\n",
    "\n",
    "            train_loss = esn.train(\n",
    "                transient_data,\n",
    "                train_data,\n",
    "                train_target,\n",
    "                regularization = hp.Float('regularization', min_value=min_reg, max_value=max_reg, step=step_reg, sampling='log'),\n",
    "            )\n",
    "\n",
    "            predictions, states_over_time, cumulative_rmse, threshold_steps = esn.forecast(forecast_length=self.forecast_length, \n",
    "                                                                            forecast_transient_data=ftransient, \n",
    "                                                                            val_data=val_data, \n",
    "                                                                            val_target=val_target,\n",
    "                                                                            internal_states=False,\n",
    "                                                                            error_threshold=0.5)\n",
    "            \n",
    "            print(f\"\\n Threshold steps: {threshold_steps}\\n\")\n",
    "            \n",
    "            results.append(threshold_steps)\n",
    "\n",
    "        mean_threshold_steps = np.mean(results)\n",
    "        \n",
    "        return mean_threshold_steps\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./src/systems/data/Lorenz/\" # change path to data csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir(data_path):\n",
    "    data_file = np.random.choice(os.listdir(data_path))\n",
    "    data_file = os.path.join(data_path, data_file)\n",
    "else:\n",
    "    data_file = data_path\n",
    "\n",
    "transient_data, train_data, train_target, ftransient, val_data, val_target = (\n",
    "    load_data(data_file, train_length=train_length)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model builder (no need to change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_model = MyHyperModel(input_shape=train_data.shape, forecast_length=forecast_length, data_path=data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can click this cell and then \"Execute above cells\" button (up arrow to the right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose type of heuristic to use (your call). Run only one of the following cells\n",
    "\n",
    "#### The first two will run for at most `max_trials` times before stopping.\n",
    "\n",
    "#### I recommend using BayesianOpt since hyperband has some troubles and random search is a no-brainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = RandomSearch(objective=kt.Objective('steps', 'max'),\n",
    "                        max_trials=max_trials,\n",
    "                        directory=directory_name,\n",
    "                        project_name=project_name,\n",
    "                        overwrite=overwrite,\n",
    "                        hypermodel=hyper_model,\n",
    "                        max_retries_per_trial=3,\n",
    "                        max_consecutive_failed_trials=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correcting spectral radius to 0.4\n",
      "Spectral radius was previously 1.9999864101409912\n"
     ]
    }
   ],
   "source": [
    "tuner = BayesianOptimization(\n",
    "    hypermodel=hyper_model,\n",
    "    objective=kt.Objective(\"steps\", \"max\"),\n",
    "    max_trials=max_trials,\n",
    "    directory=directory_name,\n",
    "    project_name=project_name,\n",
    "    overwrite=overwrite,\n",
    "    max_retries_per_trial=3,\n",
    "    max_consecutive_failed_trials=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Hyperband"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = Hyperband(\n",
    "    hypermodel=hyper_model,\n",
    "    objective=kt.Objective(\"steps\", \"max\"),\n",
    "    directory=directory_name,\n",
    "    project_name=project_name,\n",
    "    overwrite=overwrite,\n",
    "    max_retries_per_trial=3,\n",
    "    max_consecutive_failed_trials=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 136 Complete [00h 04m 26s]\n",
      "steps: 387.2\n",
      "\n",
      "Best steps So Far: 496.8\n",
      "Total elapsed time: 08h 59m 57s\n",
      "\n",
      "Search: Running Trial #137\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "0                 |2.6141e+05        |seed\n",
      "0.1               |0.1               |input_scaling\n",
      "10                |10                |degree\n",
      "1                 |1                 |spectral_radius\n",
      "0.5               |0.9               |rewiring_p\n",
      "0.82              |0.85              |leak_rate\n",
      "1e-08             |1e-09             |regularization\n",
      "\n",
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x73e7c291e5f0>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/home/elessar/.local/lib/python3.10/site-packages/keras_tuner/src/engine/tuner.py\", line 245, in _build_and_fit_model\n",
      "    return results  File \"/tmp/ipykernel_6501/96920230.py\", line 90, in fit\n",
      "    return mean_threshold_steps  File \"/media/elessar/Data/Pincha/MachineLearning/ESN/src/model.py\", line 386, in forecast\n",
      "    return (  File \"/media/elessar/Data/Pincha/MachineLearning/ESN/src/model.py\", line 480, in _perform_forecasting\n",
      "    return cumulative_error, steps_to_exceed_threshold, states_over_time  File \"/home/elessar/.local/lib/python3.10/site-packages/tensorflow/python/util/tf_should_use.py\", line 288, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n",
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x73e7c2793ee0>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/home/elessar/.local/lib/python3.10/site-packages/keras_tuner/src/engine/tuner.py\", line 245, in _build_and_fit_model\n",
      "    return results  File \"/tmp/ipykernel_6501/96920230.py\", line 90, in fit\n",
      "    return mean_threshold_steps  File \"/media/elessar/Data/Pincha/MachineLearning/ESN/src/model.py\", line 386, in forecast\n",
      "    return (  File \"/media/elessar/Data/Pincha/MachineLearning/ESN/src/model.py\", line 480, in _perform_forecasting\n",
      "    return cumulative_error, steps_to_exceed_threshold, states_over_time  File \"/home/elessar/.local/lib/python3.10/site-packages/tensorflow/python/util/tf_should_use.py\", line 288, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n",
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x73e7b0506bc0>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/home/elessar/.local/lib/python3.10/site-packages/keras_tuner/src/engine/tuner.py\", line 245, in _build_and_fit_model\n",
      "    return results  File \"/tmp/ipykernel_6501/96920230.py\", line 90, in fit\n",
      "    return mean_threshold_steps  File \"/media/elessar/Data/Pincha/MachineLearning/ESN/src/model.py\", line 386, in forecast\n",
      "    return (  File \"/media/elessar/Data/Pincha/MachineLearning/ESN/src/model.py\", line 480, in _perform_forecasting\n",
      "    return cumulative_error, steps_to_exceed_threshold, states_over_time  File \"/home/elessar/.local/lib/python3.10/site-packages/tensorflow/python/util/tf_should_use.py\", line 288, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n",
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x73e7a89add50>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/home/elessar/.local/lib/python3.10/site-packages/keras_tuner/src/engine/tuner.py\", line 245, in _build_and_fit_model\n",
      "    return results  File \"/tmp/ipykernel_6501/96920230.py\", line 90, in fit\n",
      "    return mean_threshold_steps  File \"/media/elessar/Data/Pincha/MachineLearning/ESN/src/model.py\", line 386, in forecast\n",
      "    return (  File \"/media/elessar/Data/Pincha/MachineLearning/ESN/src/model.py\", line 480, in _perform_forecasting\n",
      "    return cumulative_error, steps_to_exceed_threshold, states_over_time  File \"/home/elessar/.local/lib/python3.10/site-packages/tensorflow/python/util/tf_should_use.py\", line 288, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n",
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x73e7aaa057e0>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/home/elessar/.local/lib/python3.10/site-packages/keras_tuner/src/engine/tuner.py\", line 245, in _build_and_fit_model\n",
      "    return results  File \"/tmp/ipykernel_6501/96920230.py\", line 90, in fit\n",
      "    return mean_threshold_steps  File \"/media/elessar/Data/Pincha/MachineLearning/ESN/src/model.py\", line 386, in forecast\n",
      "    return (  File \"/media/elessar/Data/Pincha/MachineLearning/ESN/src/model.py\", line 480, in _perform_forecasting\n",
      "    return cumulative_error, steps_to_exceed_threshold, states_over_time  File \"/home/elessar/.local/lib/python3.10/site-packages/tensorflow/python/util/tf_should_use.py\", line 288, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n",
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x73e80c039780>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/home/elessar/.local/lib/python3.10/site-packages/keras_tuner/src/engine/tuner.py\", line 245, in _build_and_fit_model\n",
      "    return results  File \"/tmp/ipykernel_6501/96920230.py\", line 90, in fit\n",
      "    return mean_threshold_steps  File \"/media/elessar/Data/Pincha/MachineLearning/ESN/src/model.py\", line 386, in forecast\n",
      "    return (  File \"/media/elessar/Data/Pincha/MachineLearning/ESN/src/model.py\", line 480, in _perform_forecasting\n",
      "    return cumulative_error, steps_to_exceed_threshold, states_over_time  File \"/home/elessar/.local/lib/python3.10/site-packages/tensorflow/python/util/tf_should_use.py\", line 288, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n",
      "Correcting spectral radius to 1.0\n",
      "Spectral radius was previously 6.207676410675049\n",
      "Iteration 1 of 10\n",
      "Correcting spectral radius to 1.0\n",
      "Spectral radius was previously 6.207676410675049\n",
      "\n",
      "Ensuring ESP...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324ms/step\n",
      "Ensuring ESP took: 0.41 seconds.\n",
      "\n",
      "\n",
      "Harvesting...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "Harvesting took: 1.97 seconds.\n",
      "\n",
      "\n",
      "Calculating readout...\n",
      "Calculating readout took: 14.75 seconds.\n",
      "\n",
      "Training loss: 5.125286861584755e-10\n",
      "\n",
      "NRMSE: 1.6211170077440329e-06\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5495052fee14f78834097bf9076908f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Threshold steps: 483\n",
      "\n",
      "Iteration 2 of 10\n",
      "Correcting spectral radius to 1.0\n",
      "Spectral radius was previously 6.207676410675049\n",
      "\n",
      "Ensuring ESP...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step\n",
      "Ensuring ESP took: 0.4 seconds.\n",
      "\n",
      "\n",
      "Harvesting...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "Harvesting took: 1.94 seconds.\n",
      "\n",
      "\n",
      "Calculating readout...\n",
      "Calculating readout took: 14.04 seconds.\n",
      "\n",
      "Training loss: 5.125286861584755e-10\n",
      "\n",
      "NRMSE: 1.6211170077440329e-06\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6d31ec136dc47ddb70e3355a86a5a0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Threshold steps: -1\n",
      "\n",
      "Iteration 3 of 10\n",
      "Correcting spectral radius to 1.0\n",
      "Spectral radius was previously 6.207676410675049\n",
      "\n",
      "Ensuring ESP...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step\n",
      "Ensuring ESP took: 0.35 seconds.\n",
      "\n",
      "\n",
      "Harvesting...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "Harvesting took: 2.08 seconds.\n",
      "\n",
      "\n",
      "Calculating readout...\n",
      "Calculating readout took: 12.01 seconds.\n",
      "\n",
      "Training loss: 4.578286638690088e-10\n",
      "\n",
      "NRMSE: 1.5445104963873746e-06\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cd3fa57eec54faebcf7961a0c4c7407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Threshold steps: 505\n",
      "\n",
      "Iteration 4 of 10\n",
      "Correcting spectral radius to 1.0\n",
      "Spectral radius was previously 6.207676410675049\n",
      "\n",
      "Ensuring ESP...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step\n",
      "Ensuring ESP took: 0.37 seconds.\n",
      "\n",
      "\n",
      "Harvesting...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "Harvesting took: 1.89 seconds.\n",
      "\n",
      "\n",
      "Calculating readout...\n",
      "Calculating readout took: 12.15 seconds.\n",
      "\n",
      "Training loss: 5.386864843082151e-10\n",
      "\n",
      "NRMSE: 1.6660179653626983e-06\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6757360b8d3490ea8e7c50bed6ad788",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Threshold steps: 399\n",
      "\n",
      "Iteration 5 of 10\n",
      "Correcting spectral radius to 1.0\n",
      "Spectral radius was previously 6.207676410675049\n",
      "\n",
      "Ensuring ESP...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step\n",
      "Ensuring ESP took: 0.36 seconds.\n",
      "\n",
      "\n",
      "Harvesting...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "Harvesting took: 1.93 seconds.\n",
      "\n",
      "\n",
      "Calculating readout...\n",
      "Calculating readout took: 13.22 seconds.\n",
      "\n",
      "Training loss: 6.829631304938744e-10\n",
      "\n",
      "NRMSE: 1.8594085986478603e-06\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "017ef8ef65b644279cb13c006c63d5e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Threshold steps: 405\n",
      "\n",
      "Iteration 6 of 10\n",
      "Correcting spectral radius to 1.0\n",
      "Spectral radius was previously 6.207676410675049\n",
      "\n",
      "Ensuring ESP...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step\n",
      "Ensuring ESP took: 0.34 seconds.\n",
      "\n",
      "\n",
      "Harvesting...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "Harvesting took: 1.85 seconds.\n",
      "\n",
      "\n",
      "Calculating readout...\n",
      "Calculating readout took: 10.48 seconds.\n",
      "\n",
      "Training loss: 4.547650866992825e-10\n",
      "\n",
      "NRMSE: 1.4947052022762364e-06\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a44d90f31f8b45e9be535910c103cb2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Threshold steps: 371\n",
      "\n",
      "Iteration 7 of 10\n",
      "Correcting spectral radius to 1.0\n",
      "Spectral radius was previously 6.207676410675049\n",
      "\n",
      "Ensuring ESP...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step\n",
      "Ensuring ESP took: 0.36 seconds.\n",
      "\n",
      "\n",
      "Harvesting...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x73e7b0776080>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/home/elessar/.local/lib/python3.10/site-packages/keras_tuner/src/engine/tuner.py\", line 233, in _build_and_fit_model\n",
      "    results = self.hypermodel.fit(hp, model, *args, **kwargs)  File \"/tmp/ipykernel_6501/96920230.py\", line 70, in fit\n",
      "    train_loss = esn.train(  File \"/media/elessar/Data/Pincha/MachineLearning/ESN/src/model.py\", line 386, in forecast\n",
      "    return (  File \"/media/elessar/Data/Pincha/MachineLearning/ESN/src/model.py\", line 480, in _perform_forecasting\n",
      "    return cumulative_error, steps_to_exceed_threshold, states_over_time  File \"/home/elessar/.local/lib/python3.10/site-packages/tensorflow/python/util/tf_should_use.py\", line 288, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n",
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x73e80fc90fa0>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/home/elessar/.local/lib/python3.10/site-packages/keras_tuner/src/engine/tuner.py\", line 233, in _build_and_fit_model\n",
      "    results = self.hypermodel.fit(hp, model, *args, **kwargs)  File \"/tmp/ipykernel_6501/96920230.py\", line 70, in fit\n",
      "    train_loss = esn.train(  File \"/media/elessar/Data/Pincha/MachineLearning/ESN/src/model.py\", line 386, in forecast\n",
      "    return (  File \"/media/elessar/Data/Pincha/MachineLearning/ESN/src/model.py\", line 480, in _perform_forecasting\n",
      "    return cumulative_error, steps_to_exceed_threshold, states_over_time  File \"/home/elessar/.local/lib/python3.10/site-packages/tensorflow/python/util/tf_should_use.py\", line 288, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n",
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x73e7b0035870>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/home/elessar/.local/lib/python3.10/site-packages/keras_tuner/src/engine/tuner.py\", line 233, in _build_and_fit_model\n",
      "    results = self.hypermodel.fit(hp, model, *args, **kwargs)  File \"/tmp/ipykernel_6501/96920230.py\", line 70, in fit\n",
      "    train_loss = esn.train(  File \"/media/elessar/Data/Pincha/MachineLearning/ESN/src/model.py\", line 386, in forecast\n",
      "    return (  File \"/media/elessar/Data/Pincha/MachineLearning/ESN/src/model.py\", line 480, in _perform_forecasting\n",
      "    return cumulative_error, steps_to_exceed_threshold, states_over_time  File \"/home/elessar/.local/lib/python3.10/site-packages/tensorflow/python/util/tf_should_use.py\", line 288, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n",
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x73e801f6a7d0>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/home/elessar/.local/lib/python3.10/site-packages/keras_tuner/src/engine/tuner.py\", line 233, in _build_and_fit_model\n",
      "    results = self.hypermodel.fit(hp, model, *args, **kwargs)  File \"/tmp/ipykernel_6501/96920230.py\", line 70, in fit\n",
      "    train_loss = esn.train(  File \"/media/elessar/Data/Pincha/MachineLearning/ESN/src/model.py\", line 386, in forecast\n",
      "    return (  File \"/media/elessar/Data/Pincha/MachineLearning/ESN/src/model.py\", line 480, in _perform_forecasting\n",
      "    return cumulative_error, steps_to_exceed_threshold, states_over_time  File \"/home/elessar/.local/lib/python3.10/site-packages/tensorflow/python/util/tf_should_use.py\", line 288, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n",
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x73e7b07f1e10>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/home/elessar/.local/lib/python3.10/site-packages/keras_tuner/src/engine/tuner.py\", line 233, in _build_and_fit_model\n",
      "    results = self.hypermodel.fit(hp, model, *args, **kwargs)  File \"/tmp/ipykernel_6501/96920230.py\", line 70, in fit\n",
      "    train_loss = esn.train(  File \"/media/elessar/Data/Pincha/MachineLearning/ESN/src/model.py\", line 386, in forecast\n",
      "    return (  File \"/media/elessar/Data/Pincha/MachineLearning/ESN/src/model.py\", line 480, in _perform_forecasting\n",
      "    return cumulative_error, steps_to_exceed_threshold, states_over_time  File \"/home/elessar/.local/lib/python3.10/site-packages/tensorflow/python/util/tf_should_use.py\", line 288, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miterations\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras_tuner/src/engine/base_tuner.py:234\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_end(trial)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras_tuner/src/engine/base_tuner.py:274\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m         trial\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m trial_module\u001b[38;5;241m.\u001b[39mTrialStatus\u001b[38;5;241m.\u001b[39mCOMPLETED\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras_tuner/src/engine/base_tuner.py:239\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[0;32m--> 239\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_trial(trial\u001b[38;5;241m.\u001b[39mtrial_id)\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mexists(\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m    242\u001b[0m     ):\n\u001b[1;32m    243\u001b[0m         \u001b[38;5;66;03m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;66;03m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;66;03m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[1;32m    246\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe use case of calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    248\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    254\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    255\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras_tuner/src/engine/tuner.py:314\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(model_checkpoint)\n\u001b[1;32m    313\u001b[0m     copied_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m callbacks\n\u001b[0;32m--> 314\u001b[0m     obj_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_and_fit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcopied_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m     histories\u001b[38;5;241m.\u001b[39mappend(obj_value)\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m histories\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras_tuner/src/engine/tuner.py:233\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m hp \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39mhyperparameters\n\u001b[1;32m    232\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_build(hp)\n\u001b[0;32m--> 233\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhypermodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m# Save the build config for model loading later.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmulti_backend():\n",
      "Cell \u001b[0;32mIn[18], line 70\u001b[0m, in \u001b[0;36mMyHyperModel.fit\u001b[0;34m(self, hp, model, iterations, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild(hp)\n\u001b[1;32m     68\u001b[0m esn \u001b[38;5;241m=\u001b[39m ESN\u001b[38;5;241m.\u001b[39mfrom_model(model\u001b[38;5;241m=\u001b[39mmodel, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed)\n\u001b[0;32m---> 70\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mesn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransient_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_target\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43mregularization\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mhp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFloat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mregularization\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_reg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_reg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep_reg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlog\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m predictions, states_over_time, cumulative_rmse, threshold_steps \u001b[38;5;241m=\u001b[39m esn\u001b[38;5;241m.\u001b[39mforecast(forecast_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforecast_length, \n\u001b[1;32m     78\u001b[0m                                                                 forecast_transient_data\u001b[38;5;241m=\u001b[39mftransient, \n\u001b[1;32m     79\u001b[0m                                                                 val_data\u001b[38;5;241m=\u001b[39mval_data, \n\u001b[1;32m     80\u001b[0m                                                                 val_target\u001b[38;5;241m=\u001b[39mval_target,\n\u001b[1;32m     81\u001b[0m                                                                 internal_states\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     82\u001b[0m                                                                 error_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Threshold steps: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mthreshold_steps\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/media/elessar/Data/Pincha/MachineLearning/ESN/src/model.py:219\u001b[0m, in \u001b[0;36mESN.train\u001b[0;34m(self, transient_data, train_data, train_target, regularization)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    202\u001b[0m     transient_data: np\u001b[38;5;241m.\u001b[39mndarray,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m     regularization: \u001b[38;5;28mfloat\u001b[39m,\n\u001b[1;32m    206\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;124;03m    Training process of the model.\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;124;03m        None\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 219\u001b[0m     harvested_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_harvest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransient_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     training_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calculate_readout(\n\u001b[1;32m    222\u001b[0m         harvested_states, train_target, regularization\n\u001b[1;32m    223\u001b[0m     )\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mModel(\n\u001b[1;32m    226\u001b[0m         inputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreservoir\u001b[38;5;241m.\u001b[39minputs,\n\u001b[1;32m    227\u001b[0m         outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreadout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreservoir\u001b[38;5;241m.\u001b[39moutput),\n\u001b[1;32m    228\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mESN\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    229\u001b[0m     )\n",
      "File \u001b[0;32m/media/elessar/Data/Pincha/MachineLearning/ESN/src/model.py:156\u001b[0m, in \u001b[0;36mESN._harvest\u001b[0;34m(self, transient_data, train_data)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreservoir\u001b[38;5;241m.\u001b[39mpredict(transient_data)\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m timer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHarvesting\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 156\u001b[0m     harvested_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreservoir\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m harvested_states\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:517\u001b[0m, in \u001b[0;36mTensorFlowTrainer.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    513\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_predict_end()\n\u001b[1;32m    514\u001b[0m outputs \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mmap_structure_up_to(\n\u001b[1;32m    515\u001b[0m     batch_outputs, potentially_ragged_concat, outputs\n\u001b[1;32m    516\u001b[0m )\n\u001b[0;32m--> 517\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert_to_np_if_not_ragged\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/tree/tree_api.py:148\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structures)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.tree.map_structure\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap_structure\u001b[39m(func, \u001b[38;5;241m*\u001b[39mstructures):\n\u001b[1;32m    126\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Maps `func` through given structures.\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m    Examples:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;124;03m        A new structure with the same layout as the given ones.\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtree_impl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstructures\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/tree/optree_impl.py:79\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structures)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m other \u001b[38;5;129;01min\u001b[39;00m structures[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[1;32m     78\u001b[0m     assert_same_structure(structures[\u001b[38;5;241m0\u001b[39m], other, check_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_map\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstructures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnone_is_leaf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkeras\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     81\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/optree/ops.py:594\u001b[0m, in \u001b[0;36mtree_map\u001b[0;34m(func, tree, is_leaf, none_is_leaf, namespace, *rests)\u001b[0m\n\u001b[1;32m    592\u001b[0m leaves, treespec \u001b[38;5;241m=\u001b[39m _C\u001b[38;5;241m.\u001b[39mflatten(tree, is_leaf, none_is_leaf, namespace)\n\u001b[1;32m    593\u001b[0m flat_args \u001b[38;5;241m=\u001b[39m [leaves] \u001b[38;5;241m+\u001b[39m [treespec\u001b[38;5;241m.\u001b[39mflatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rests]\n\u001b[0;32m--> 594\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtreespec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflat_args\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:868\u001b[0m, in \u001b[0;36mconvert_to_np_if_not_ragged\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, tf\u001b[38;5;241m.\u001b[39mRaggedTensor):\n\u001b[1;32m    867\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m--> 868\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:407\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m--> 407\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:373\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m npt\u001b[38;5;241m.\u001b[39mArrayLike:\n\u001b[1;32m    372\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 373\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    374\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tuner.search(iterations=iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the best hyperparams from the tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the values of the best hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the best model using the best hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyHyperModel(input_shape=(train_data.shape), forecast_length=1000, data_path=data_path).build(best_hps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate the best ESN from the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esn = ESN.from_model(model=model, seed=best_hps.get('seed'))\n",
    "\n",
    "esn.train(\n",
    "    transient_data,\n",
    "    train_data,\n",
    "    train_target,\n",
    "    regularization=best_hps.get('regularization')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make your predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_length = 1000\n",
    "forecast,states,loss,threshold_steps = esn.forecast(\n",
    "                                      forecast_length=forecast_length, \n",
    "                                      forecast_transient_data=ftransient, \n",
    "                                      val_data=val_data, \n",
    "                                      val_target=val_target,\n",
    "                                      internal_states=False,\n",
    "                                      error_threshold=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save your model if you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"name_and_path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 0.02\n",
    "features = train_data.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "# plot each forecast feature in a subplot, the shape of data is (batch, time, features)\n",
    "fig, axs = plt.subplots(features, 1, figsize=(15, 3))\n",
    "for i in range(features):\n",
    "    axs[i].plot([j*dt for j in range(len(forecast[0, :forecast_length, i]))],val_target[0, :forecast_length, i], label='target')\n",
    "    axs[i].plot([j*dt for j in range(len(forecast[0, :forecast_length, i]))], forecast[0, :forecast_length, i], label='forecast')\n",
    "    axs[i].legend()\n",
    "    # set y range to be from -25 to 25\n",
    "    axs[i].set_ylim(-25, 25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
